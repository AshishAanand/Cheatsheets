# Machine Learning Terminologies

A concise reference guide for essential machine learning concepts and terms.

## 10 Essential Machine Learning Terms

### 1. Overfitting
**Definition:** When a model learns the training data too well, including its noise and outliers, causing poor performance on new, unseen data.

**Simple explanation:** Like memorizing exam answers without understanding the concepts, making it impossible to solve new problems.

### 2. Underfitting
**Definition:** When a model is too simple to capture the underlying pattern in the data, resulting in poor performance on both training and new data.

**Simple explanation:** Using a linear model to predict highly non-linear data - too simplistic to capture the true relationship.

### 3. Bias
**Definition:** Systematic error in model predictions that causes the model to consistently miss the true relationship.

**Simple explanation:** When your model consistently predicts values that are too high or too low compared to actual values.

### 4. Variance
**Definition:** The sensitivity of a model to fluctuations in the training data.

**Simple explanation:** How much your model's predictions would change if trained on a different dataset. High variance means the model changes significantly with different training data.

### 5. Feature Engineering
**Definition:** The process of selecting, transforming, or creating features (input variables) to improve model performance.

**Simple explanation:** Preparing and refining your input data to make it more useful for your model, like extracting important information from raw data.

### 6. Hyperparameters
**Definition:** Configuration settings for machine learning algorithms that are set before training begins.

**Simple explanation:** The "knobs" you adjust before training a model, like learning rate or tree depth, as opposed to model parameters which are learned during training.

### 7. Cross-Validation
**Definition:** A technique for evaluating model performance by partitioning the data into multiple training and testing sets.

**Simple explanation:** Testing your model on different subsets of your data to ensure it performs consistently across all of them.

### 8. Gradient Descent
**Definition:** An iterative optimization algorithm used to find the minimum of a function by moving in the direction of the steepest descent.

**Simple explanation:** A method for finding the best model parameters by repeatedly taking small steps in the direction that reduces error the most.

### 9. Regularization
**Definition:** Techniques that penalize model complexity to prevent overfitting.

**Simple explanation:** Adding constraints to your model that prevent it from becoming too complex or memorizing the training data.

### 10. Confusion Matrix
**Definition:** A table used to describe the performance of a classification model, showing true positives, false positives, true negatives, and false negatives.

**Simple explanation:** A scorecard that shows how well your model identifies different classes, revealing not just overall accuracy but specific types of errors.